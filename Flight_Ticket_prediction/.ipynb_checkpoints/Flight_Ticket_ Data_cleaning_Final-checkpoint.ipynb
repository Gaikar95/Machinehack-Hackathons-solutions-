{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1663aa",
   "metadata": {},
   "source": [
    "FLIGHT TICKET PRICE PREDICTION - Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c109256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cf2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel('Data_Train.xlsx')\n",
    "test_data = pd.read_excel('Test_Set.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train_data, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba931ac",
   "metadata": {},
   "source": [
    "# Checking and imputing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88937d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df['Route'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[(combined_df['Source'] == 'Delhi') &\n",
    "                           (combined_df['Destination'] == 'Cochin') & \n",
    "                           (combined_df['Price']== 7480.0)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Route'].fillna('DEL → MAA → COK', inplace=True)\n",
    "combined_df['Total_Stops'].fillna('1 stop', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21bdfea",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Date and Time from Arrival_Time column\n",
    "combined_df['Arrival_Date'] = combined_df['Arrival_Time'].str.split(' ').str[1] + ' ' + combined_df['Arrival_Time'].str.split(' ').str[2]\n",
    "combined_df['Arrival_Time'] = combined_df['Arrival_Time'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84215286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date time columns to datetime format\n",
    "combined_df['Date_of_Journey'] = pd.to_datetime(combined_df['Date_of_Journey'], format='%d/%m/%Y')\n",
    "combined_df['Arrival_Date'] = pd.to_datetime(combined_df['Arrival_Date'], format='%d %b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c854a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day and month from 'Date_of_Journey'\n",
    "combined_df['Journey_Day'] = combined_df['Date_of_Journey'].dt.day\n",
    "combined_df['Journey_Month'] = combined_df['Date_of_Journey'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing Null Arrival_Date to same day as Date_of_Journey\n",
    "combined_df.loc[combined_df['Arrival_Date'].isnull(), 'Arrival_Date'] = combined_df.loc[combined_df['Arrival_Date'].isnull(), 'Date_of_Journey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80683b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day and month from 'Arrival_Date'\n",
    "combined_df['Arrival_Day'] = combined_df['Arrival_Date'].dt.day.astype(int)\n",
    "combined_df['Arrival_Month'] = combined_df['Arrival_Date'].dt.month.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df['Arrival_Day'] < combined_df['Journey_Day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21168c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of flights by Date_of_Journey\n",
    "journey_counts = combined_df['Date_of_Journey'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.bar(journey_counts.index, journey_counts.values, color='blue')\n",
    "plt.title('Number of Flights by Date_of_Journey')\n",
    "plt.xlabel('Date_of_Journey')\n",
    "plt.ylabel('Number of Flights')\n",
    "plt.xticks(journey_counts.index, journey_counts.index.strftime('%Y-%m-%d'), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575aea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Swap dates where Arrival date is earlier than Journey date\n",
    "# condition = combined_df['Arrival_Day'] < combined_df['Journey_Day']\n",
    "# combined_df.loc[condition, 'Arrival_Day'] = combined_df.loc[condition, 'Journey_Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.drop(['Arrival_Date','Date_of_Journey'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Total_Stops'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to the 'Total_Stops' column\n",
    "stops_mapping = {'non-stop': 0,'1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4}\n",
    "combined_df['Total_Stops'] = combined_df['Total_Stops'].map(stops_mapping)\n",
    "\n",
    "combined_df['Additional_Info'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59195b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'No info' with 'No Info'\n",
    "combined_df['Additional_Info'] = combined_df['Additional_Info'].replace('No info', 'No Info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818b31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f94598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dep_Time to datetime format\n",
    "combined_df['Dep_Time'] = pd.to_datetime(combined_df['Dep_Time'])\n",
    "\n",
    "# Convert Arrival_Time to datetime format\n",
    "combined_df['Arrival_Time'] = pd.to_datetime(combined_df['Arrival_Time'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d80e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Diff_Duration'] = combined_df['Arrival_Time'] - combined_df['Dep_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Duration'] = pd.to_timedelta(combined_df['Duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d84099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[(combined_df['Duration'] != combined_df['Diff_Duration'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea26742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'Arrival_Day' and 'Arrival_Time' for those rows\n",
    "condition = combined_df['Duration'] != combined_df['Diff_Duration']\n",
    "rows_to_update = combined_df[condition]\n",
    "\n",
    "new_arrival_time = rows_to_update['Dep_Time'] + rows_to_update['Duration']\n",
    "\n",
    "combined_df.loc[condition, 'Arrival_Day'] = new_arrival_time.dt.day\n",
    "combined_df.loc[condition, 'Arrival_Time'] = new_arrival_time\n",
    "combined_df['Diff_Duration'] = combined_df['Arrival_Time'] - combined_df['Dep_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[(combined_df['Duration'] != combined_df['Diff_Duration'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baad995",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(['Diff_Duration'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca269264",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52096cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Houe and Minute from date_time formats\n",
    "combined_df['Dep_Hour'] = combined_df['Dep_Time'].dt.hour\n",
    "combined_df['Dep_Minute'] = combined_df['Dep_Time'].dt.minute\n",
    "combined_df['Arrival_Hour'] = combined_df['Arrival_Time'].dt.hour\n",
    "combined_df['Arrival_Minute'] = combined_df['Arrival_Time'].dt.minute\n",
    "\n",
    "# Calculate Duration in minute\n",
    "combined_df['Duration'] = (combined_df['Arrival_Time'] - combined_df['Dep_Time']).dt.total_seconds() / 60\n",
    "\n",
    "# Drop original datetime columns\n",
    "combined_df.drop(['Dep_Time', 'Arrival_Time'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns to plot Boxplot\n",
    "numerical_columns = ['Duration', 'Price']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(numerical_columns)//2, ncols=2, figsize=(14, 3))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(numerical_columns):\n",
    "    sns.boxplot(x=combined_df[col], ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aac738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cfbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Additional_Info'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c808ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['airline_speciality'] = combined_df['Airline'].apply(lambda x: 'Premium economy' if 'Premium economy' in x else ('Business' if 'Business' in x else '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Airline'] = combined_df['Airline'].str.replace(' Premium economy', '')\n",
    "combined_df['Airline'] = combined_df['Airline'].str.replace(' Business', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['In-flight_meal'] = np.where(combined_df['Additional_Info'] == 'In-flight meal not included', 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['layover'] = np.where(combined_df['Additional_Info'].astype(str).str.contains('layover', case=False), 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df[combined_df['Additional_Info'].str.contains('layover', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Column_name\\t unique_values \\t {\"DataType\".rjust(10)} \\t {\"Minimum\".rjust(15)} \\t {\"Maximum\".rjust(10)} ')\n",
    "for colum in combined_df.columns:\n",
    "    print(f'{colum.center(20)} {str(len(combined_df[colum].unique())).rjust(5)} \\t {str(combined_df[colum].dtype).rjust(10)} \\t {str(combined_df[colum].min()).rjust(15)} \\t {str(combined_df[colum].max()).rjust(10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4307ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_date = pd.to_datetime('1/1/2020')\n",
    "combined_df['day_diff'] = (reference_date - combined_df['Date_of_Journey']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Arrival_Date'] = combined_df['Arrival_Date'].apply(lambda x: x.replace(year=2019) if x.year != 2019 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeece412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the distribution of 'Price'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(combined_df['Price'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Flight Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63dbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Log transform the 'Price' column\n",
    "combined_df['Log_Price'] = np.log1p(combined_df['Price'])\n",
    "\n",
    "# Plot the distribution of the log-transformed 'Price'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(combined_df['Log_Price'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Log-Transformed Flight Prices')\n",
    "plt.xlabel('Log(Price + 1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32cc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16549fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab58647",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Num_Layovers'] = combined_df['Route'].str.count('→')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "categorical_columns = combined_df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(categorical_columns)\n",
    "for column in categorical_columns:\n",
    "    combined_df[column] = le.fit_transform(combined_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix  = combined_df.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(['Total_Stops','Arrival_Month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f209e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving Price column to last index\n",
    "price_column = combined_df.pop('Price')\n",
    "combined_df['Price'] = price_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "features_to_scale = combined_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "features_to_scale.remove('Price')\n",
    "features_to_scale.remove('Log_Price') \n",
    "\n",
    "scaler = StandardScaler()\n",
    "combined_df[features_to_scale] = scaler.fit_transform(combined_df[features_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c23498",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(['Date_of_Journey','Arrival_Date'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Train and test data based on presence of Price\n",
    "train_data = combined_df[combined_df['Price'].notnull()]\n",
    "test_data = combined_df[combined_df['Price'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns=['Price','Log_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c196861",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Price','Log_Price'])  # Features (all columns except 'Price')\n",
    "y = train_data['Log_Price']  # Target variable ('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99402fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a97dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af6997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583908e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ec012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Support Vector Machine': SVR(),\n",
    "    'k-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Neural Network': MLPRegressor(max_iter=3000),\n",
    "    'Gaussian Process': GaussianProcessRegressor(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LightGBM': LGBMRegressor(verbose=0),\n",
    "    'CatBoost': CatBoostRegressor(verbose=0) \n",
    "}\n",
    "\n",
    "# Train the models and evaluate\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    score = model.score(X_test,y_test)\n",
    "    \n",
    "    print(f\"Mean Squared Error ({name}): {mse} , Score : {score}\")\n",
    "    \n",
    " \n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_score= score\n",
    "        best_model = model\n",
    "\n",
    "print(f\"The best model is {type(best_model).__name__} with an MSE of {best_mse} and score {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92537217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e17a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f793f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed80eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define a dictionary to store the top 3 best parameters for XGBoost\n",
    "top_params_xgboost = []\n",
    "\n",
    "# Define the objective function for XGBoost optimization\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 5000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "    model = XGBRegressor(**params, objective='reg:squarederror', verbosity=0)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error as the objective to minimize\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Store the top 3 best parameters for XGBoost\n",
    "    top_params_xgboost.append((mse, params))\n",
    "    top_params_xgboost.sort()\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Create the Optuna study and optimize the objective function for XGBoost\n",
    "study_xgboost = optuna.create_study(direction='minimize')\n",
    "study_xgboost.optimize(objective_xgboost, n_trials=150)\n",
    "\n",
    "# Print the top 3 best parameters for XGBoost\n",
    "print(\"Top 3 Best Parameters for XGBoost:\")\n",
    "for i, (mse, params) in enumerate(top_params_xgboost[:3], 1):\n",
    "    print(f\"  Rank {i}: Mean Squared Error = {mse}, Parameters = {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7af31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define a dictionary to store the top 3 best parameters for LightGBM\n",
    "top_params_lightgbm = []\n",
    "\n",
    "# Define the objective function for LightGBM optimization\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 5000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.35),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "#     params = {\n",
    "#     'n_estimators': trial.suggest_int('n_estimators', 50, 5000),\n",
    "#     'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "#     'max_depth': trial.suggest_int('max_depth', -1, 20),  # -1 means no limit\n",
    "#     'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 1.0),\n",
    "#     'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#     'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#     'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "#     'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "#     'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'rf']),\n",
    "#     'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "#     'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n",
    "#     'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "#     'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "#     'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "#     'subsample_freq': trial.suggest_int('subsample_freq', 0, 10),\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': trial.suggest_categorical('n_jobs', [None, -1, 1]),  # Use -1 for all threads, None for default\n",
    "# }\n",
    "    model = LGBMRegressor( **params,verbose=-1)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error as the objective to minimize\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Store the top 3 best parameters for LightGBM\n",
    "    top_params_lightgbm.append((mse, params))\n",
    "    top_params_lightgbm.sort()\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Create the Optuna study and optimize the objective function for LightGBM\n",
    "study_lightgbm = optuna.create_study(direction='minimize')\n",
    "study_lightgbm.optimize(objective_lightgbm, n_trials=150)\n",
    "\n",
    "# Print the top 3 best parameters for LightGBM\n",
    "print(\"Top 3 Best Parameters for LightGBM:\")\n",
    "for i, (mse, params) in enumerate(top_params_lightgbm[:3], 1):\n",
    "    print(f\"  Rank {i}: Mean Squared Error = {mse}, Parameters = {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafde417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define a dictionary to store the top 3 best parameters for CatBoost\n",
    "top_params_catboost = []\n",
    "\n",
    "# Define the objective function for CatBoost optimization\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 5000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 1.0),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 1, 255),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10.0),\n",
    "    }\n",
    "    model = CatBoostRegressor(**params, verbose=0)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error as the objective to minimize\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Store the top 3 best parameters for CatBoost\n",
    "    top_params_catboost.append((mse, params))\n",
    "    top_params_catboost.sort()\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Create the Optuna study and optimize the objective function for CatBoost\n",
    "study_catboost = optuna.create_study(direction='minimize')\n",
    "study_catboost.optimize(objective_catboost, n_trials=150)\n",
    "\n",
    "# Print the top 3 best parameters for CatBoost\n",
    "print(\"Top 3 Best Parameters for CatBoost:\")\n",
    "for i, (mse, params) in enumerate(top_params_catboost[:3], 1):\n",
    "    print(f\"  Rank {i}: Mean Squared Error = {mse}, Parameters = {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697df322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define a dictionary to store the top 3 best parameters for Random Forest\n",
    "top_params_random_forest = []\n",
    "\n",
    "# Define the objective function for Random Forest optimization\n",
    "def objective_random_forest(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 5000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "#         'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "#     }\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['squared_error', 'absolute_error']),\n",
    "        'max_samples': trial.suggest_float('max_samples', 0.1, 1.0, step=0.1),\n",
    "        'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5, step=0.1),\n",
    "    }\n",
    "    model = RandomForestRegressor(**params, random_state=42)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error as the objective to minimize\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Store the top 3 best parameters for Random Forest\n",
    "    top_params_random_forest.append((mse, params))\n",
    "    top_params_random_forest.sort()\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Create the Optuna study and optimize the objective function for Random Forest\n",
    "study_random_forest = optuna.create_study(direction='minimize')\n",
    "study_random_forest.optimize(objective_random_forest, n_trials=150)\n",
    "\n",
    "# Print the top 3 best parameters for Random Forest\n",
    "print(\"Top 3 Best Parameters for Random Forest:\")\n",
    "for i, (mse, params) in enumerate(top_params_random_forest[:3], 1):\n",
    "    print(f\"  Rank {i}: Mean Squared Error = {mse}, Parameters = {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee8910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Assuming you have X and y defined\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define a dictionary to store the top 3 best parameters for KNN\n",
    "top_params_knn = []\n",
    "\n",
    "# Define the objective function for KNN optimization\n",
    "def objective_knn(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 200)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    p = trial.suggest_int('p', 1, 2),\n",
    "    if algorithm in['ball_tree', 'kd_tree']:\n",
    "        leaf_size = trial.suggest_int('leaf_size',1,100)\n",
    "\n",
    "\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error as the objective to minimize\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Store the top 3 best parameters for KNN\n",
    "    top_params_knn.append((mse, {'n_neighbors': n_neighbors, 'weights': weights, 'algorithm': algorithm}))\n",
    "    top_params_knn.sort(key=lambda x: x[0])\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Create the Optuna study and optimize the objective function for KNN\n",
    "study_knn = optuna.create_study(direction='minimize')\n",
    "study_knn.optimize(objective_knn, n_trials=150)\n",
    "\n",
    "# Print the top 3 best parameters for KNN\n",
    "print(\"Top 3 Best Parameters for KNN:\")\n",
    "for i, (mse, params) in enumerate(top_params_knn[:3], 1):\n",
    "    print(f\"  Rank {i}: Mean Squared Error = {mse}, Parameters = {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45dafaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a85561",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_catboost = [item[1] for item in top_params_catboost[:3]]\n",
    "best_params_xgboost = [item[1] for item in top_params_xgboost[:3]]\n",
    "best_params_lightgbm = [item[1] for item in top_params_lightgbm[:3]]\n",
    "best_params_random_forest = [item[1] for item in top_params_random_forest[:3]]\n",
    "best_params_knn = [item[1] for item in top_params_knn[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b111551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    'CatBoost': CatBoostRegressor(**best_params_catboost[0], verbose=0),\n",
    "    'CatBoost1': CatBoostRegressor(**best_params_catboost[1], verbose=0),\n",
    "    'CatBoost2': CatBoostRegressor(**best_params_catboost[2], verbose=0),\n",
    "    'XGBoost': XGBRegressor(**best_params_xgboost[0], objective='reg:squarederror', verbosity=0),\n",
    "    'XGBoost1': XGBRegressor(**best_params_xgboost[1], objective='reg:squarederror', verbosity=0),\n",
    "    'XGBoost2': XGBRegressor(**best_params_xgboost[2], objective='reg:squarederror', verbosity=0),\n",
    "    'LightGBM': LGBMRegressor(**best_params_lightgbm[0], verbose=-1),\n",
    "    'LightGBM1': LGBMRegressor(**best_params_lightgbm[1], verbose=-1),\n",
    "    'LightGBM2': LGBMRegressor(**best_params_lightgbm[2], verbose=-1),\n",
    "    'RandomForest': RandomForestRegressor(**best_params_random_forest[0], random_state=42),\n",
    "    'RandomForest1': RandomForestRegressor(**best_params_random_forest[1], random_state=42),\n",
    "    'RandomForest2': RandomForestRegressor(**best_params_random_forest[2], random_state=42),\n",
    "    'knn': KNeighborsRegressor(**best_params_knn[0]),\n",
    "    'knn1': KNeighborsRegressor(**best_params_knn[1]),\n",
    "    'knn2': KNeighborsRegressor(**best_params_knn[2])   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58b5cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "ensembles = {\n",
    "    'Stacking': StackingRegressor(estimators=list(models.items()), final_estimator=Ridge(), cv=5),\n",
    "    'Voting': VotingRegressor(estimators=list(models.items())),\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train and evaluate each ensemble method\n",
    "for ensemble_name, ensemble_model in ensembles.items():\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    y_pred = ensemble_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error ({ensemble_name}): {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prediction=0\n",
    "model_predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    model_predictions[model_name] = predictions\n",
    "    sum_prediction= predictions + sum_prediction\n",
    "    mse= mean_squared_error(y_test, predictions)\n",
    "    print(f'mean squared error - {model_name}: {mse}')\n",
    "    \n",
    "Ensemble_pred= sum_prediction/len(models)\n",
    "Ensemble_mse= mean_squared_error(y_test, Ensemble_pred)\n",
    "print(f'mean squared error - Ensemble: {Ensemble_mse}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44370b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "prediction_sets = model_predictions\n",
    "\n",
    "# Get the list of prediction set names\n",
    "prediction_set_names = list(prediction_sets.keys())\n",
    "\n",
    "# Define a function to compute the average of a list of prediction sets\n",
    "def compute_average(prediction_sets_list):\n",
    "    return sum(prediction_sets_list) / len(prediction_sets_list)\n",
    "\n",
    "best_combo_mse= float('inf')\n",
    "for r in range(1, len(prediction_set_names) + 1):\n",
    "    for combo in itertools.combinations(prediction_set_names, r):\n",
    "        combination_name = '_'.join(combo) + '_avg'\n",
    "        combination_prediction_sets = [prediction_sets[model] for model in combo]\n",
    "        average_prediction = compute_average(combination_prediction_sets)\n",
    "        Ensemble_mse= mean_squared_error(y_test, average_prediction)\n",
    "#         print(f'Log Loss - {combo} Ensemble: {Ensemble_mse}')\n",
    "        if Ensemble_mse < best_combo_mse:\n",
    "            best_combo_mse =Ensemble_mse\n",
    "            best_combo = combo\n",
    "print(f'\\nbest combo: {best_combo} \\t mse {best_combo_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994af086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prediction=0\n",
    "final_model_predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    if model_name in best_combo:\n",
    "        model.fit(X, y)\n",
    "        predictions = model.predict(test_data)\n",
    "        model_predictions[model_name + '_pred'] = predictions\n",
    "        sum_prediction= predictions + sum_prediction\n",
    "    \n",
    "Ensemble_pred= sum_prediction/len(best_combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8401d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ece74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = np.expm1(Ensemble_pred)\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Price': predicted_prices,\n",
    "})\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "print(predictions_df)\n",
    "predictions_df.to_excel(\"log_predictions.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72c252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b36d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043051e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
