{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030b0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc041622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel('Data_Train.xlsx')\n",
    "test_data = pd.read_excel('Data_Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3d7ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3e9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.concat([train_data, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b31d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b5378d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Preprocessing: Tokenization and Vectorization\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "x = vectorizer.fit_transform(train_data['STORY'])\n",
    "y = vectorizer.transform(test_data['STORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf77fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.9593709043250328\n",
      "Random Forest Score: 0.9515072083879423\n",
      "Support Vector Machine Score: 0.9311926605504587\n",
      "K-Nearest Neighbors Score: 0.63564875491481\n",
      "Gradient Boosting Score: 0.9325032765399738\n",
      "Multilayer Perceptron Score: 0.9678899082568807\n",
      "\n",
      "The best model is Multilayer Perceptron with a score of 0.9678899082568807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, train_data['SECTION'], test_size=0.2)\n",
    "\n",
    "# Define a list of models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Support Vector Machine', SVC()),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('Multilayer Perceptron', MLPClassifier(max_iter=1000))\n",
    "]\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_model_score = 0\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'{name} Score: {score}')\n",
    "    \n",
    "    if score > best_model_score:\n",
    "        best_model_score = score\n",
    "        best_model_name = name\n",
    "\n",
    "print(f'\\nThe best model is {best_model_name} with a score of {best_model_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ecf5f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7628x32518 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 377305 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58167d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb929f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd21896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Preprocessing: Tokenization and Vectorization\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_data['STORY'])\n",
    "X_test = vectorizer.transform(test_data['STORY'])\n",
    "\n",
    "# Define the target variable for X_train\n",
    "y_train = train_data['SECTION']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = MLPClassifier(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict SECTION for y_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The variable y_pred contains the predicted SECTION for test_data['STORY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a39246",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.DataFrame({'SECTION': y_pred})\n",
    "\n",
    "output_data.to_csv('predicted_sections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f3cc924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5050725e-19 1.0000000e+00 8.3883091e-22 5.1179241e-20]\n",
      " [2.3157797e-03 2.0017563e-03 9.9527007e-01 4.1241152e-04]\n",
      " [7.2889289e-19 1.0000000e+00 7.1107095e-21 2.8929182e-18]\n",
      " ...\n",
      " [2.5733907e-08 9.9999988e-01 1.8212249e-09 7.7343032e-08]\n",
      " [9.5538270e-01 8.3472170e-03 2.5145590e-08 3.6270056e-02]\n",
      " [1.9022194e-05 9.9968755e-01 1.7284764e-06 2.9172120e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcbe2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9475753604193972\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "\n",
    "train_data = pd.read_excel('Data_Train.xlsx')\n",
    "test_data = pd.read_excel('Data_Test.xlsx')\n",
    "\n",
    "# Preprocess the data (remove punctuation, stopwords, etc.)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data['STORY'], train_data['SECTION'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_data['STORY'])\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = clf.predict(X_test_tfidf)\n",
    "\n",
    "# The 'test_predictions' variable now contains the predicted categories for the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d48b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49fc03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.DataFrame({'SECTION': test_predictions})\n",
    "\n",
    "output_data.to_csv('predicted_sections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268590e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
